{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently use following device :  cpu\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Meaning of MLP\n",
    "    - 1. Create MLP by using Pytorch.\n",
    "    - 2. MLP is the Model that connect Linear-Layer.\n",
    "    - 3. It has Input-Layer, Middle-Layer, and Hidden-Layer.\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "# Scikit-Learn Model.\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "\n",
    "# Set Activation-Function by using 'nn.Sequential'.\n",
    "# (It might be better to say generate not Setting.)\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 10)\n",
    ")\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"Currently use following device : \", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you apply 'nn.Sequential' by Stacked Layer 'nn.Module',\n",
    "# it means that you construct Neural-Network.\n",
    "# This procedure we call as 'FeedForward'.\n",
    "\n",
    "# For example of 'FeedForward', it applys 'Back-Propagation-Algorithm'\n",
    "# when get the answer of Differentation.\n",
    "\n",
    "# 'nn.ReLU()' is the activation-function that use generally for\n",
    "# training Neural-Network.\n",
    "X = digits.data\n",
    "Y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'ndarry' of 'Numpy' as a Tensor of Pytorch.\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "Y = torch.tensor(Y, dtype=torch.int64)\n",
    "\n",
    "# SoftMax Cross-Entropy\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "# Log of Loss-Function.\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterates 100 times\n",
    "for epoch in range(100):\n",
    "    # Delete before value that calculated by backward Method.\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Calculate 'y' prediction value by Linear-Model.\n",
    "    y_pred = net(X)\n",
    "    \n",
    "    # Calculate differentation by applying 'MSE-loss' and 'w'.\n",
    "    loss = loss_fn(y_pred, Y)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update Regression\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Record variable 'loss' for convergence confirmation.\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For subsequent processing, \n",
    "# set the optimizer equally and rotate the learning loop.\n",
    "# Do not set as 'if' phrase to distinguish which device does I use.\n",
    "# If you set the code that distinguish as using 'if' phrase, \n",
    "# it will occurs lots of error in your code.\n",
    "X = X.to(DEVICE)\n",
    "Y = Y.to(DEVICE)\n",
    "net.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

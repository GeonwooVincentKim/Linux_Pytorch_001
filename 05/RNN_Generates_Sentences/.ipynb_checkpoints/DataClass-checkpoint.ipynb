{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import tqdm\n",
    "\n",
    "import import_ipynb\n",
    "from Vocabulary_Dictionary_and_Two_Convert_Function import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, path, chunk_size=200):\n",
    "        # Convert Read file to Numerical-List.\n",
    "        data = str2ints(open(path).read().strip(), vocab_dict)\n",
    "        \n",
    "        # Convert files as Tensor, and then split it.\n",
    "        data = torch.tensor(data, dtype=torch.int64).split(chunk_size)\n",
    "        \n",
    "        # Throw-away the length of last-chunk if has no enough data.\n",
    "        if len(data[-1]) < chunk_size:\n",
    "            data = data[:-1]\n",
    "    \n",
    "        self.data = data\n",
    "        self.n_chunks = len(self.data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_chunks\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Downloaded input.txt from\n",
    "    'char-rnn/data/tinyshakespeare/input.txt'\n",
    "    that the author of this project named\n",
    "    karpathy.\n",
    "    \n",
    "    Download from here\n",
    "    https://github.com/karpathy/char-rnn/tree/master/data/tinyshakespeare\n",
    "\"\"\"\n",
    "ds = ShakespeareDataset(\"../05/input.txt\",\n",
    "                       chunk_size=200)\n",
    "loader = DataLoader(ds, batch_size=32, shuffle=True,\n",
    "                   num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceGenerationNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_embeddings,\n",
    "        embedding_dim=50,\n",
    "        hidden_size=50,\n",
    "        num_layers=1, dropout=0.2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # The size of Linear of output is same as the num_embeddings\n",
    "        # that is same with Embedding of input-size.\n",
    "        self.linear = nn.Linear(hidden_size, num_embeddings)\n",
    "        \n",
    "    def forward(self, x, h0=None):\n",
    "        x = self.emb(x)\n",
    "        x, h = self.lstm(x, h0)\n",
    "        x = self.linear(x)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function that generates sentences.\n",
    "def generate_seq(net, start_phrase=\"The King said \",\n",
    "                length=200, temperature=0.8, device=\"cpu\"):\n",
    "    # Set Model as a Evaluation-Mode.\n",
    "    net.eval()\n",
    "    \n",
    "    # THe List that saves Output-Figures.\n",
    "    result = []\n",
    "    \n",
    "    # Convert Start-String as a Tensor.\n",
    "    start_tensor = torch.tensor(\n",
    "        str2ints(start_phrase, vocab_dict),\n",
    "        dtype=torch.int64\n",
    "    ).to(device)\n",
    "    \n",
    "    # Attach Batch-Dimension to the front-side.\n",
    "    x0 = start_tensor.unsqueeze(0) \n",
    "    \n",
    "    # Get Output and Inner-state by RNN-Model.\n",
    "    o, h = net(x0)\n",
    "    \n",
    "    # Convert output to non-normalize probability.(\n",
    "    out_dist = o[:, -1].view(-1).exp()\n",
    "    \n",
    "    # Sampling Real-Text(Message)-Indext from probability.\n",
    "    top_i = torch.multinomial(out_dist, 1)[0]\n",
    "    \n",
    "    # Save Result\n",
    "    result.append(top_i)\n",
    "    \n",
    "    # Input Generated-Result to the RNN orderly.\n",
    "    for i in range(length):\n",
    "        inp = torch.tensor([[top_i]], dtype=torch.int64)\n",
    "        inp = inp.to(device)\n",
    "        o, h = net(inp, h)\n",
    "        \n",
    "        out_dist = o.view(-1).exp()\n",
    "        top_i = torch.multinomial(out_dist, 1)[0]\n",
    "        result.append(top_i)\n",
    "    \n",
    "    # Return Start-String and Generated-String by gathering together.\n",
    "    return start_phrase + ints2str(result, all_chars)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

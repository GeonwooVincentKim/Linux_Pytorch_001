{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Displaying Device :  cpu\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import tqdm\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import FashionMNIST, ImageFolder\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from IPython.display import Image, display_jpeg\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DISPLAY = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"Current Displaying Device : \", DISPLAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSizedPairImageFolder(ImageFolder):\n",
    "    def __init__(self, root, transform=None,\n",
    "                large_size=128, small_size=32, **kwds):\n",
    "        super().__init__(root, transform=transform, **kwds)\n",
    "        self.large_resizer = transforms.Resize(large_size)\n",
    "        self.small_resizer = transforms.Resize(small_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = ImageFolder(\n",
    "    \"../04/oxford-102/\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(80),\n",
    "        transforms.CenterCrop(64),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "img_loader = DataLoader(img_data, batch_size=batch_size,\n",
    "                       shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = 100\n",
    "ngf = 32\n",
    "\n",
    "in_size = 1\n",
    "stride = 1\n",
    "padding = 0\n",
    "kernel_size = 4\n",
    "output_padding = 0\n",
    "\n",
    "\"\"\"\n",
    "    The meaning of 3 is 3-Color.\n",
    "    (Maybe RGB(?))\n",
    "    \n",
    "    Create 'z', a Hidden-Vector Variable as 100-Dimension.\n",
    "    And then construct create-model that generates Image as 3 X 64 X 64\n",
    "    from 'z', a Hidden-Vector Variable.\n",
    "    \n",
    "    Generate Image-Creation-Model.\n",
    "\"\"\"\n",
    "class GNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Convert Image-Size here by Transposed-Convolution.\n",
    "            nn.ConvTranspose2d(\n",
    "                nz, ngf * 8,\n",
    "                4, 1, 0, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(\n",
    "                ngf * 8, ngf * 4,\n",
    "                4, 2, 1, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(\n",
    "                ngf * 4, ngf * 2,\n",
    "                4, 2, 1, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(\n",
    "                ngf * 2, ngf,\n",
    "                4, 2, 1, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(\n",
    "                ngf, 3,\n",
    "                4, 2, 1, bias=False\n",
    "            ),\n",
    "            # You can iterate ConvTranspose2d code\n",
    "            # At this point.\n",
    "            # out_size = (in_size - 1) * stride - 2 * padding \\\n",
    "            #    + kernel_size + output_padding\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "                \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.main(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Recognition Model\n",
    "\"\"\"\n",
    "ndf = 32\n",
    "\n",
    "\n",
    "class DNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2 , inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.main(x)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNet(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (5): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (8): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (11): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "d = DNet().to(DISPLAY)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNet(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace)\n",
      "    (9): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace)\n",
      "    (12): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "g = GNet().to(DISPLAY)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Parameter of Adam is the suggest value from Original-Paper.\n",
    "opt_d = optim.Adam(d.parameters(),\n",
    "                  lr=0.0002, betas=(0.5, 0.999))\n",
    "opt_g = optim.Adam(g.parameters(),\n",
    "                  lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Create auxiliary variable that calculate Cross-Entropy.\n",
    "ones = torch.ones(batch_size).to(DISPLAY)\n",
    "print(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "zeros = torch.zeros(batch_size).to(DISPLAY)\n",
    "print(zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCEWithLogitsLoss()\n"
     ]
    }
   ],
   "source": [
    "loss_f = nn.BCEWithLogitsLoss()\n",
    "print(loss_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.2117]],\n",
      "\n",
      "         [[-0.4615]],\n",
      "\n",
      "         [[ 0.1435]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1226]],\n",
      "\n",
      "         [[-1.2850]],\n",
      "\n",
      "         [[-1.7076]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2447]],\n",
      "\n",
      "         [[ 0.5307]],\n",
      "\n",
      "         [[ 1.4886]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7857]],\n",
      "\n",
      "         [[ 0.6485]],\n",
      "\n",
      "         [[-0.1108]]],\n",
      "\n",
      "\n",
      "        [[[-3.3730]],\n",
      "\n",
      "         [[ 1.3246]],\n",
      "\n",
      "         [[ 0.9811]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3080]],\n",
      "\n",
      "         [[-0.6699]],\n",
      "\n",
      "         [[-0.5819]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6629]],\n",
      "\n",
      "         [[ 0.2512]],\n",
      "\n",
      "         [[-0.0570]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.7630]],\n",
      "\n",
      "         [[-0.5362]],\n",
      "\n",
      "         [[ 0.2871]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8671]],\n",
      "\n",
      "         [[-1.2520]],\n",
      "\n",
      "         [[-1.5471]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2694]],\n",
      "\n",
      "         [[ 0.1731]],\n",
      "\n",
      "         [[ 0.3693]]],\n",
      "\n",
      "\n",
      "        [[[-0.5105]],\n",
      "\n",
      "         [[ 0.6021]],\n",
      "\n",
      "         [[ 1.2014]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3666]],\n",
      "\n",
      "         [[-0.6115]],\n",
      "\n",
      "         [[ 0.5021]]]])\n"
     ]
    }
   ],
   "source": [
    "# For Monitoring, the Variable 'z'.\n",
    "fixed_z = torch.randn(batch_size, nz, 1, 1).to(DISPLAY)\n",
    "print(fixed_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Classification by using CNN-Algorithm.\n",
    "# Now we are going to use Fashion-MNIST while we train and test this model.\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring the Training-Data.\n",
    "# Create DataSet that is the Initial-State as a PIL Image-Shape.\n",
    "fashion_mnist_train = FashionMNIST(\n",
    "    \"../04/FashionMNIST\",\n",
    "    train=True, download=True,\n",
    "    transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring vertify-Data.\n",
    "fashion_mnist_test = FashionMNIST(\n",
    "    \"../04/FashionMNIST\",\n",
    "    train=False, download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create each of DataLoader which Batch-Size are 128.\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(fashion_mnist_train,\n",
    "                         batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(fashion_mnist_test,\n",
    "                        batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increate Layer such as shape of (N, C, H, W) Tensor to the \n",
    "# (N, C*H*W).\n",
    "# It needs for print Convolution-Product.\n",
    "class FlatternLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        sizes = x.size()\n",
    "        return x.view(sizes[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 32-Channels that initialized by using 5 x 5 Kernel,\n",
    "# And then create 64-Channels.\n",
    "# Apply Batch-Normalization to the BatchNorm2d as a Image-Data,\n",
    "# and apply Dropout to the Dropout2d as a Image-Data,\n",
    "# and lastly, apply FlatternLayer to the Image-Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_net = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.Dropout2d(0.25),\n",
    "    nn.Conv2d(32, 64, 5),\n",
    "    \n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Dropout2d(0.25),\n",
    "    FlatternLayer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, check the Image-Size by Dummy-Data by Convolution Product.\n",
    "test_input = torch.ones(1, 1, 28, 28)\n",
    "conv_output_size = conv_net(test_input).size()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-Layer MLP\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(conv_output_size, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(200),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear(200, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final-CNN\n",
    "net = nn.Sequential(\n",
    "    conv_net,\n",
    "    mlp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate-Function Helper\n",
    "def eval_net(net, data_loader, device=\"cpu\"):\n",
    "    # Invalidation Dropout and BatchNorm\n",
    "    net.eval()\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    \n",
    "    for x, y, in data_loader:\n",
    "        # Send to Device that executes calculations to the 'to method'.\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Because forward calculations are all here, \n",
    "        # the processing required for automatic differentials is set to off \n",
    "        # to limit unnecessary calculations.\n",
    "        with torch.no_grad():\n",
    "            _y, y_pred = net(x).max(1)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "        \n",
    "    # The results of the prediction of the mini-deployment \n",
    "    # unit are grouped together.\n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    \n",
    "    # Calculate Prediction-Accuracy\n",
    "    acc = (ys == ypreds).float().sum() / len(ys)\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:10<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4615211274443019 0.8401833333333333 0.878000020980835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:09<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.316070291126131 0.8849666666666667 0.8970000147819519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:07<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.2796245135175876 0.8981833333333333 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:09<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.2574094804879437 0.9052333333333333 0.9086999893188477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:10<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.24447691324365955 0.9098166666666667 0.9111999869346619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:08<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.22957709460304335 0.9144333333333333 0.9122999906539917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:07<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.21875363760269606 0.9182 0.90420001745224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:06<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.21000619138726312 0.9224166666666667 0.9176999926567078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:05<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.20285779849076882 0.9242 0.9157999753952026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:04<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.1951042563519162 0.9275333333333333 0.9150999784469604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:06<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.1902173175675492 0.9294833333333333 0.9180999994277954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:05<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.18263612015761882 0.9316833333333333 0.9200999736785889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:04<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.17606976666511634 0.93345 0.9193000197410583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:15<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.16997338697696343 0.9357166666666666 0.920199990272522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:17<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.1686167555869135 0.9373 0.9215999841690063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:09<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.16324561693442938 0.9389666666666666 0.917900025844574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 382/469 [00:59<00:21,  4.07it/s]"
     ]
    }
   ],
   "source": [
    "# Training-Function Helper\n",
    "def train_net(net, train_loader, test_loader,\n",
    "             optimizer_cls=optim.Adam,\n",
    "             loss_fn=nn.CrossEntropyLoss(),\n",
    "             n_iter=10, device=\"cpu\"):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    optimizer = optimizer_cls(net.parameters())\n",
    "    \n",
    "    for epoch in range(n_iter):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Set Neura-Network as Training-Mode.\n",
    "        net.train()\n",
    "        n = 0\n",
    "        n_acc = 0\n",
    "        \n",
    "        # It takes a lot of time, \n",
    "        # so use tqdm to display Progress-Bar.\n",
    "        for i, (xx, yy) in tqdm.tqdm(\n",
    "            enumerate(train_loader),\n",
    "            total=len(train_loader)):\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            \n",
    "            h = net(xx)\n",
    "            loss = loss_fn(h, yy)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            n += len(xx)\n",
    "            _, y_pred = h.max(1)\n",
    "            n_acc += (yy == y_pred).float().sum().item()\n",
    "        \n",
    "        train_losses.append(running_loss / i)\n",
    "        # Prediction Accuracy of Train-Data.\n",
    "        train_acc.append(n_acc / n)\n",
    "        \n",
    "        # Prediction Accuracy of Verify-Data.\n",
    "        val_acc.append(eval_net(net, test_loader, device))\n",
    "        \n",
    "        # Display epoch result.\n",
    "        print(epoch, train_losses[-1], train_acc[-1],\n",
    "             val_acc[-1], flush=True)\n",
    "        \n",
    "# Send all of Neural-Network's Parameter to the GPU\n",
    "# (But I'm going to use CPU)\n",
    "net.to(\"cpu\")\n",
    "\n",
    "# Execution Training\n",
    "train_net(net, train_loader, test_loader, n_iter=20,\n",
    "         device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
